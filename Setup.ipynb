{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "1Nt81FY66EM3"
   },
   "source": [
    "# hardware and OS\n",
    "To run this repo, you need 1 to 8 GPUs with CUDA. If you don't have a Nvidia Graphic card, no problem! This notebook is intended to run on Google Colab!\n",
    "\n",
    "Don't forget to activate the GPU in **Goolgle Colab** ([how to](https://jovianlin.io/pytorch-with-gpu-in-google-colab/)) If you do not enable GPU from the beggining then you will have to restart te setup from beggining\n",
    "\n",
    "If using **Kaggle kernel** do not forget to enable internet\n",
    "\n",
    "**OS:** It is almost impossible to run this repo on Windows (believe me, I tried hard) because of many dependencies that are made for Linux. So better continue with Linux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Environment setup\n",
    "before installing anything related to this project, first you need a version of PyTorch compatible with your GPU settings\n",
    "\n",
    "with the 2 line script below you can check if your environment is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting environment information...\n",
      "PyTorch version: 1.5.0+cu101\n",
      "Is debug build: No\n",
      "CUDA used to build PyTorch: 10.1\n",
      "\n",
      "OS: Ubuntu 16.04.4 LTS\n",
      "GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\n",
      "CMake version: Could not collect\n",
      "\n",
      "Python version: 3.7\n",
      "Is CUDA available: Yes\n",
      "CUDA runtime version: 10.1.105\n",
      "GPU models and configuration: \n",
      "GPU 0: Tesla K80\n",
      "GPU 1: Tesla K80\n",
      "\n",
      "Nvidia driver version: 430.26\n",
      "cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.4\n",
      "[pip3] torch==1.5.0+cu101\n",
      "[pip3] torchvision==0.6.0+cu101\n",
      "[conda] mkl                       2018.0.1             h19d6760_4  \n",
      "[conda] mkl-service               1.1.2            py36h17a0993_4  \n",
      "[conda] numpy                     1.18.4                   pypi_0    pypi\n",
      "[conda] numpydoc                  0.7.0            py36h18f165f_0  \n",
      "[conda] torch                     1.5.0+cu101              pypi_0    pypi\n",
      "[conda] torchvision               0.6.0+cu101              pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "! wget --quiet \"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\"\n",
    "! python collect_env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first, check that your computer detect your graphic card ``GPU 0: ...``\n",
    "- second, you need a driver to use your GPU for any application: ``Nvidia driver version: ...``\n",
    "- third, you need some libraries to run any data science algorith on your GPU: ``cuDNN version: ...`` and ``CUDA runtime version: ...``\n",
    "- fourth, you need to install Pytorch after having all the things above so that Pytorch is built using the CUDA library: ``PyTorch version: 1.5.0+cu101`` and ``CUDA used to build PyTorch: 10.1``\n",
    "- Finally, if your are on windows, you might also need ``Microsoft Visual C++ 14.0``\n",
    "\n",
    "If any of these are missing, the project setup will probably fail somewhere. Below are the instruction to fix your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "! apt-get update\n",
    "! pip install --upgrade pip\n",
    "\n",
    "! apt-get install linux-headers-$(uname -r)\n",
    "! apt-get -y install cmake\n",
    "\n",
    "! conda update conda\n",
    "! conda update conda-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!gcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "hidden": true,
    "id": "U5vDdOhoxBtR",
    "outputId": "d5db9410-345d-423c-e7bc-91483a7f88ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Fri_Feb__8_19:08:17_PST_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.105\r\n"
     ]
    }
   ],
   "source": [
    "# this command must work otherwise check the symLink /usr/local/cuda\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA\n",
    "Note that each version of CUDA has a minimum requirement concerning the version of the driver\n",
    "\n",
    "\n",
    "cuda toolkit: https://developer.nvidia.com/cuda-10.1-download-archive-base?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal\n",
    "example of thing you should install XD\n",
    "```\n",
    "wget https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.105_418.39_linux.run\n",
    "sh cuda_10.1.105_418.39_linux.run\n",
    "```\n",
    "\n",
    "## libnccl\n",
    "Nvidia NCCL can be downloaded from: https://developer.nvidia.com/nccl/nccl-download (you need to create a free account)\n",
    "\n",
    "## libcudnn\n",
    "do not download ``libcudnn-dev``\n",
    "\n",
    "then install it using this command ``dpkg -i libcudnn7_7.6.5.32-1+cuda10.1_amd64.deb``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "Get the command line that fits your hardware on this web site: https://pytorch.org/get-started/locally/\n",
    "For example you should run something like the line below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now run the command below to see if Pytorch detects your GPUs\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Nt81FY66EM3"
   },
   "source": [
    "# Install the requirements\n",
    "[github source](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-A87_S0JsZq"
   },
   "source": [
    "## Python libraries\n",
    "Might take 5 to 10 mins to install all the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ipython scipy h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ninja yacs cython matplotlib tqdm opencv-python overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrNKakC2i839"
   },
   "source": [
    "ends with `Successfully installed ninja-1.9.0.post1 overrides-3.0.0 yacs-0.1.7`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFWyA5T359_6"
   },
   "source": [
    "## install PyCOCO tools (cocoapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "8c47j7kQ3EtZ",
    "outputId": "8606dbc5-5bd1-4605-fa48-001e6c1e8355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cocoapi'...\n",
      "remote: Enumerating objects: 975, done.\u001b[K\n",
      "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
      "Receiving objects: 100% (975/975), 11.72 MiB | 3.13 MiB/s, done.\n",
      "Resolving deltas: 100% (576/576), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/cocodataset/cocoapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MOCeqEFb5t8s",
    "outputId": "05a89365-331e-406e-b8cb-f022819d3f8a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cd cocoapi/PythonAPI; python setup.py build_ext install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OndJ9TRUpvm"
   },
   "source": [
    "ends with \n",
    "\n",
    "```\n",
    "Finished processing dependencies for pycocotools==2.0\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ2Eoix66NLA"
   },
   "source": [
    "## install apex\n",
    "it is a PyTorch extension for easy mixed precision and distributed training in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/NVIDIA/apex.git\n",
    "! cd apex ; python setup.py install --cuda_ext --cpp_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ2Eoix66NLA"
   },
   "source": [
    "### method 2\n",
    "https://stackoverflow.com/questions/57284345/how-to-install-nvidia-apex-on-google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "yu08H3016Qud",
    "outputId": "54c04e0f-6f85-4c8d-81fe-e48bcd2453d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-nx74GTK6-6T",
    "outputId": "50f56b3b-6680-429b-8097-6f6f24b71cce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sh setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -v --no-cache-dir ./apex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEuiRUr2U42g"
   },
   "source": [
    "ends with\n",
    "```\n",
    "Successfully installed apex-0.1\n",
    "Cleaning up...\n",
    "Removed build tracker '/tmp/pip-req-tracker-yl9p9317'\n",
    "```\n",
    "\n",
    "\"A Python-only build\" omits:\n",
    "* Fused kernels **required** to use apex.optimizers.FusedAdam.\n",
    "* Fused kernels **required** to use apex.normalization.FusedLayerNorm.\n",
    "* Fused kernels that improve the performance and numerical stability of apex.parallel.SyncBatchNorm.\n",
    "* Fused kernels that improve the performance of apex.parallel.DistributedDataParallel and apex.amp. DistributedDataParallel, amp, and SyncBatchNorm will still be usable, but they may be slower.\n",
    "\n",
    "AMP: Automatic Mixed Precision: https://nvidia.github.io/apex/amp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfnfJLGb7GSY"
   },
   "source": [
    "## install PyTorch Detection (Scene-Graph-Benchmark.pytorch)\n",
    "We change the file name from `Scene-Graph-Benchmark.pytorch` to `Scene`\n",
    "because *ninja* can not handel certain characters in the directory's name\n",
    "([source](https://stackoverflow.com/questions/54569963/error-building-depfile-has-multiple-output-paths-ninja-build-stopped-subcomm ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "QrQhyUTS7Fnj",
    "outputId": "1a77bc42-3376-4b68-d247-fccc6e4d79e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Scene-Graph-Benchmark.pytorch'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 462 (delta 1), reused 0 (delta 0), pack-reused 451\u001b[K\n",
      "Receiving objects: 100% (462/462), 26.17 MiB | 12.90 MiB/s, done.\n",
      "Resolving deltas: 100% (150/150), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch.git Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "adnO822q8mPB",
    "outputId": "cf05fe69-e504-4bb2-c88e-291902fbbe93"
   },
   "outputs": [],
   "source": [
    "# you can also rename it using this cmd\n",
    "# ! mv Scene-Graph-Benchmark.pytorch Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "B72Lk4W_86Kq",
    "outputId": "bf692be0-36e0-4110-a35e-52cb780dcd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running build_py\n",
      "running build_ext\n",
      "building 'maskrcnn_benchmark._C' extension\n",
      "Emitting ninja build file /root/Scene/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] /usr/local/cuda/bin/nvcc -DWITH_CUDA -I/root/Scene/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.cu -o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "[2/2] /usr/local/cuda/bin/nvcc -DWITH_CUDA -I/root/Scene/maskrcnn_benchmark/csrc -I/opt/conda/lib/python3.7/site-packages/torch/include -I/opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.7/site-packages/torch/include/TH -I/opt/conda/lib/python3.7/site-packages/torch/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.7m -c -c /root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.cu -o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/vision.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cpu/nms_cpu.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cpu/ROIAlign_cpu.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/ROIAlign_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_kernel_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/nms.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_pool_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_kernel_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/deform_conv_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/SigmoidFocalLoss_cuda.o /root/Scene/build/temp.linux-x86_64-3.7/root/Scene/maskrcnn_benchmark/csrc/cuda/ROIPool_cuda.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so\n",
      "running develop\n",
      "running egg_info\n",
      "creating maskrcnn_benchmark.egg-info\n",
      "writing maskrcnn_benchmark.egg-info/PKG-INFO\n",
      "writing dependency_links to maskrcnn_benchmark.egg-info/dependency_links.txt\n",
      "writing top-level names to maskrcnn_benchmark.egg-info/top_level.txt\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "reading manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "writing manifest file 'maskrcnn_benchmark.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "copying build/lib.linux-x86_64-3.7/maskrcnn_benchmark/_C.cpython-37m-x86_64-linux-gnu.so -> maskrcnn_benchmark\n",
      "Creating /opt/conda/lib/python3.7/site-packages/maskrcnn-benchmark.egg-link (link to .)\n",
      "Adding maskrcnn-benchmark 0.1 to easy-install.pth file\n",
      "\n",
      "Installed /root/Scene\n",
      "Processing dependencies for maskrcnn-benchmark==0.1\n",
      "Finished processing dependencies for maskrcnn-benchmark==0.1\n"
     ]
    }
   ],
   "source": [
    "! cd Scene; python setup.py build develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrKqXJxATmhD"
   },
   "source": [
    "ends with:\n",
    "\n",
    "\n",
    "```\n",
    "Installed /content/Scene\n",
    "Processing dependencies for maskrcnn-benchmark==0.1\n",
    "Finished processing dependencies for maskrcnn-benchmark==0.1\n",
    "```\n",
    "otherwise you can get:\n",
    "~~~\n",
    "RuntimeError: Error compiling objects for extension\n",
    "~~~\n",
    "\n",
    "\n",
    "The line above might not work for many reasons:\n",
    "* ninja is not installed\n",
    "* the folder name contains crasy characters like space, points\n",
    "* other reasons\n",
    "\n",
    "follow carefully the instructions above to avoid any problem :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additionnal instructions for Windows:\n",
    "You might incounter this issue https://github.com/facebookresearch/maskrcnn-benchmark/issues/547\n",
    "then you might need to run that first:\n",
    "```\n",
    "set \"VS150COMNTOOLS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\"\n",
    "set CMAKE_GENERATOR=Visual Studio 16 2019 Win64\n",
    "set DISTUTILS_USE_SDK=1\n",
    "call \"%VS150COMNTOOLS%\\vcvarsall.bat\" x64 -vcvars_ver=14.11\n",
    "python setup.py build develop\n",
    "call \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat\"  x64 -vcvars_ver=14.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bkpjGsSB88xK"
   },
   "source": [
    "# DATASET\n",
    "## VG images\n",
    "Download the VG images part1 (9 Gb) part2 (5 Gb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-04 13:58:39--  https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5471658058 (5.1G) [application/zip]\n",
      "Saving to: ‘images2.zip’\n",
      "\n",
      "images2.zip         100%[===================>]   5.10G  4.98MB/s    in 30m 18s \n",
      "\n",
      "2020-06-04 14:28:57 (2.87 MB/s) - ‘images2.zip’ saved [5471658058/5471658058]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please Extract these images to the directory datasets/vg/VG_100K/ \n",
    "\n",
    "If you want to use other directory, please link it in `DATASETS['VG_stanford_filtered']['img_dir']` of `maskrcnn_benchmark/config/paths_catelog.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAZMM7VGYhiV"
   },
   "source": [
    "## SGG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhUwA2fXfOJ2"
   },
   "source": [
    "The following code does this automatically:\n",
    "\n",
    "Download the [scene graphs](https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779871&authkey=AA33n7BRpB1xa3I) to `Scene/datasets/vg/VG-SGG-with-attri.h5` (144 Mb)\n",
    "\n",
    "or you can edit the path in `DATASETS['VG_stanford_filtered_with_attribute']['roidb_file']` of `maskrcnn_benchmark/config/paths_catelog.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-3.11.0.tar.gz (8.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.46.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.23.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.14.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.11.0-py3-none-any.whl size=9619 sha256=184ea18d44683eac553a1b7705ea72a9ec3cf61445acecbfd08fdcf3912a97bb\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/e6/10/9cbfea8dcf9fde0f406da1e4c71d5c3cf3c99e0502d7f08ac6\n",
      "Successfully built gdown\n",
      "Installing collected packages: filelock, gdown\n",
      "Successfully installed filelock-3.0.12 gdown-3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively\n",
    "! gdown \"https://drive.google.com/uc?id=1h2XzeQgJNYgg3q66t1oujofbWvBIYMXG\" -O /content/Scene/maskrcnn_benchmark/data/datasets/vg/VG-SGG-with-attri.h5\n",
    "# miror link for manual download https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779871&authkey=AA33n7BRpB1xa3I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "0RWl450VelIL",
    "outputId": "4208b01b-9db9-41dc-8512-3d6dadde72f9"
   },
   "outputs": [],
   "source": [
    "! ls -l --block-size=M \"/content/Scene/maskrcnn_benchmark/datasets/vg\"\n",
    "# file size should be 144M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qI9-clPcvy7u"
   },
   "source": [
    "## Pretrained models\n",
    "\n",
    "do not name any directory `checkpoints` with an ``s`` because you will not be able to explore it using jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir Scene/checkpoint/pretrained_faster_rcnn/\n",
    "cd Scene/checkpoint/pretrained_faster_rcnn/\n",
    "gdown \"https://drive.google.com/uc?id=1GoUdVlwZ8ekS7w_aWJ-tcXsx-ULCCjyI\" -O log.txt\n",
    "gdown \"https://drive.google.com/uc?id=1Pj8gfFBouqaKzJVkOV6wsY8GU60z6Nrb\" -O config.yml\n",
    "gdown \"https://drive.google.com/uc?id=1TRT3uX0tbqvIfNeL3bRGzVeqKS8SHtFa\" -O model_final.pth\n",
    "gdown \"https://drive.google.com/uc?id=1Y1SnKGeQCBqGmIpUa8izy2EvUYLyPc89\" -O VG_stanford_filtered_wth_attribute_train_statistics.cache\n",
    "gdown \"https://drive.google.com/uc?id=1_aRGThcciCvg0gFLr9EkhLIE92vEitfP\" -O labels.json\n",
    "gdown \"https://drive.google.com/uc?id=1q6w_tZzhKTx70hgmQ-7Rnlt4EM60MmXp\" -O last_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the links above are dead you can download and extract the files manually following this:\n",
    "\n",
    "- [download the Faster R-CNN model](https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779870&authkey=AH5CPVb9g5E67iQ),\n",
    "- extract all the files to the directory `/home/username/checkpoints/pretrained_faster_rcnn`. \n",
    "\n",
    "To train your own Faster R-CNN model, please follow [the next section](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch#pretrained-models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJtSgl0_AQFS"
   },
   "source": [
    "# Setup done !\n",
    "# Training and Testing\n",
    "## Settings\n",
    "The default settings are under\n",
    "\n",
    "`configs/e2e_relation_X_101_32_8_FPN_1x.yaml` ([see on github](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch/blob/db02790a60bb9b9f7c270352820968b2f2089469/configs/e2e_relation_X_101_32_8_FPN_1x.yaml#L74))\n",
    "and\n",
    "`maskrcnn_benchmark/config/defaults.py` (todo find link in github)\n",
    "\n",
    "The priority is in this order `command > yaml > defaults.py`\n",
    "\n",
    "* For Predicate Classification (PredCls), we need to set:\n",
    "```\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True\n",
    "```\n",
    "\n",
    "* For Unbiased-Causal-TDE Model:\n",
    "```\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bRZcrKc8KOQ8"
   },
   "source": [
    "## Example 1 : (PreCls, Motif Model)\n",
    "### Training Example 1 : (PreCls, Motif Model)\n",
    "\n",
    "`CUDA_VISIBLE_DEVICES=0,1` <-- will use GPU 0 and 1\n",
    "\n",
    "`python -m torch.distributed.launch` <-- will run the script across multiple GPUs\n",
    "\n",
    "`--master_port 10025` <-- the value itself is not important, just use a free port\n",
    "\n",
    "`--nproc_per_node=2` <-- [{num_gpus}](https://docs.fast.ai/distributed.html): this should correspond to the number of gpu you specified up\n",
    "\n",
    "\n",
    "`tools/relation_train_net.py` <-- the script to run by the \"torch.distributed\". Mainly we want to train the model, or resume the training\n",
    "`--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\"` <-- Config file for all what we didn't specify\n",
    "`MODEL.ROI_RELATION_HEAD.USE_GT_BOX True ` <-- \n",
    "`MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True ` <-- This means that the ground truth object labels are provided as input to the model.\n",
    "\n",
    "`MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor ` <-- round truth bounding boxes are provided as input to the model.\n",
    "\n",
    "`SOLVER.IMS_PER_BATCH 12` <--        **this number must be divisible by the number of GPUs (2) used.**\n",
    "\n",
    "`TEST.IMS_PER_BATCH 2` <--            **must be equal to the number of GPUs (2) used.**\n",
    "\n",
    "`DTYPE \"float16\" ` <-- \n",
    "\n",
    "`SOLVER.MAX_ITER 50000 ` <-- number of epoch, there is also EarlyStopping implemented\n",
    "\n",
    "`SOLVER.VAL_PERIOD 2000 ` <-- run validation every 2 000 epochs\n",
    "\n",
    "`SOLVER.CHECKPOINT_PERIOD 2000 ` <-- create a checkpoint every 2000 epochs (1 hour or more)\n",
    "\n",
    "`GLOVE_DIR /home/kaihua/glove ` <-- directory where the pretrained word embeddings will be downloaded and stored\n",
    "\n",
    "`MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoint/pretrained_faster_rcnn/model_final.pth ` <-- \n",
    "\n",
    "`OUTPUT_DIR /home/kaihua/checkpoints/motif-precls-exmp` <-- where the model is saved. if the directory is not empty then the training is automatically resumed. So you can for example stop training and add more GPUs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T23:17:20.248013Z",
     "start_time": "2020-06-06T20:29:36.423378Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "VOjDcyrBARwv",
    "outputId": "4022a460-2711-4dea-df2a-76c050e0f776",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10025 --nproc_per_node=8 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \\\n",
    "SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" \\\n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/motif-precls-exmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_743-_bXXil"
   },
   "source": [
    "### Test Example 1 : (PreCls, Motif Model)\n",
    "Better use only one GPU for testing\n",
    "~~~\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "python -m torch.distributed.launch \n",
    "--master_port 10027 \n",
    "--nproc_per_node=1\n",
    "~~~\n",
    "\n",
    "`tools/relation_test_net.py` <-- this line is the only that change\n",
    "\n",
    "~~~\n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\"\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \n",
    "~~~\n",
    "`TEST.IMS_PER_BATCH 1` <----------------------------- must be equal to nproc_per_node\n",
    "~~~\n",
    "DTYPE \"float16\" \n",
    "GLOVE_DIR /home/kaihua/glove \n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoints/motif-precls-exmp \n",
    "OUTPUT_DIR checkpoints/motif-precls-exmp\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10027 --nproc_per_node=8 tools/relation_test_net.py \\\n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \\\n",
    "TEST.IMS_PER_BATCH 32 DTYPE \"float16\" \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/motif-precls-exmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test Example 2 : (SGCls, Causal, TDE, SUM Fusion, MOTIFS Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  python -m torch.distributed.launch --master_port 10026 --nproc_per_node=2 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none \n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\  \n",
    "SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" \\ \n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\ \n",
    "GLOVE_DIR /home/kaihua/glove \n",
    "MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoints/pretrained_faster_rcnn/model_final.pth \n",
    "OUTPUT_DIR /home/kaihua/checkpoints/causal-motifs-sgcls-exmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10028 --nproc_per_node=1 tools/relation_test_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" MODEL.ROI_RELATION_HEAD.USE_GT_BOX True MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs  TEST.IMS_PER_BATCH 1 DTYPE \"float16\" GLOVE_DIR /home/kaihua/glove MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoints/causal-motifs-sgcls-exmp OUTPUT_DIR /home/kaihua/checkpoints/causal-motifs-sgcls-exmp"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
